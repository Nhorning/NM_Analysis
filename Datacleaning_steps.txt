
Steps to clean data in Nepal Monitor data set: 


Data is probably already in flat file format. 

Ideas:

1. For their own analysis NM has provided a cleaned up version of the 2017 data certified to have no duplicates. Compare the data in the No duplicates 2017 file to the no duplicates to the standard export.  What are the differences?

2. Remove any duplicates from the 2016 data 
    Find events in the same within the same place and time, and review manually. 
    
3. Append 2017 and 2016 data to ensure a dataset with now duplicates.

4. The UNRCO has provided a new system of place codes, which converts the old system of HLCIT codes used to identify political boundaries down to the ward level into the new official Federal state set up. Map the clean dataframes to the new federal structrues. (also do this for the population by ward data and update it on HDX)


Actual steps: 

Data import:  
   Remove Errant comma from line 6055 of 1519759656_39328483.csv and save new file with cohrent file name - NM2016_17export.csv
   Attempt reinport
   Check in new files
   
   Eyeball the difference in both. it's clear by the row numbers there are significant differences. Looks like the dates are different too. Let's convert them into a date series object. Needed to find fuction for converting dates from xlsx format.

    Remove times from both dfs so we are only working with dates
    Reindex dfs by incident number and sort by index
    write function to verify the dates are the same where the incident numbers are the same. 
   
 Notes: 
  
  Empty rows? 
  Columns? 
  
  If you do ones's and 0....  Don't worry about converting columns. 
  Begin to run different functions in python, identify blanks / outliers, use code to prove that there are or are not problems. 
